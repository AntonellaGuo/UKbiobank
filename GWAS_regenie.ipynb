{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f60629-54b8-4313-a36f-c788d91bcbce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dxpy #是 DNAnexus 平台的官方 Python SDK。在 Notebook 中直访问、管理DNAnexus 上的项目和数据文件。\n",
    "import dxdata #是 DNAnexus 提供的 数据接口层（data access layer）。它主要用于加载大型数据集\n",
    "import pandas as pd #处理小规模表格数据（比如几千行）\n",
    "import pyspark #是 Apache Spark 的 Python 接口（API）。在Python环境里使用Spark 的分布式计算功能。\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28fc58af-c84d-48dc-a661-463ccc068d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246311, 11)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################phenotype data##############################\n",
    "#a. Initialize Spark\n",
    "sc = pyspark.SparkContext() #启动 Spark 的计算引擎（SparkContext\n",
    "spark = pyspark.sql.SparkSession(sc) #创建一个 SparkSession 对象，它是你和 Spark 交互的\"入口”。\n",
    "\n",
    "#b. Load dataset description：\n",
    "dispensed_dataset = dxpy.find_one_data_object( typename = \"Dataset\", name = \"app*.dataset\",folder = \"/\",name_mode = \"glob\")#在你的 DNAnexus 项目里搜索符合条件的dataset\n",
    "dispensed_dataset_id = dispensed_dataset[\"id\"] #提取出那个数据集的唯一 ID\n",
    "dataset = dxdata.load_dataset(id = dispensed_dataset_id)#加载这个数据集\n",
    "dir(dataset)#查看这个数据集的所有属性与方法\n",
    "dataset.entities_by_name #查看包含所有的entity\n",
    "\n",
    "#c. Select entity and load cohort\n",
    "participant = dataset['participant'] #从dataset取出名为participant entity(就是一张表)。\n",
    "participant.fields #可以看到所有的field ID\n",
    "case = dxdata.load_cohort(\"urticaria_case\") #从 DNAnexus 项目中加载名队列（cohort）对象。\n",
    "cont = dxdata.load_cohort(\"urticaria_control\") # 加载对照组。\n",
    "\n",
    "#d. Select fields\n",
    "#要从 participant对象中提取的字段，字段可以在建立cohort时看到。\n",
    "field_ids = ['31', '22001','22006','22019','22021','21022','41270']\n",
    "\n",
    "#function用来找到每个field id的field name\n",
    "def fields_for_id(field_id):\n",
    "    from distutils.version import LooseVersion\n",
    "    field_id = str(field_id)\n",
    "    fields = participant.find_fields(name_regex=r'^p{}(_i\\d+)?(_a\\d+)?$'.format(field_id))\n",
    "    return sorted(fields, key=lambda f: LooseVersion(f.name))\n",
    "\n",
    "# 找出所有field_ids对应的field name\n",
    "fields = [participant.find_field(name='eid')] + [fields_for_id(f)[0] for f in field_ids] + [participant.find_field(name='p20160_i0')]\n",
    "\n",
    "#转化为可读表格\n",
    "field_description = pd.DataFrame({\n",
    "    'Field': [f.name for f in fields],\n",
    "    'Title': [f.title for f in fields],\n",
    "    'Coding' : [f.coding.codes if f.coding is not None else '' for f in fields]\n",
    "})\n",
    "\n",
    "#e. Retrieve fields and concatenate cohorts\n",
    "case_df = participant.retrieve_fields(fields = fields, filter_sql = case.sql, engine = dxdata.connect()).toPandas()\n",
    "#提取病例组的参与者数据\n",
    "cont_df = participant.retrieve_fields(fields = fields, filter_sql = cont.sql, engine = dxdata.connect(dialect = 'hive+pyspark', connect_args = {'config': {'spark.kryoserializer.buffer.max': '256m', 'spark.sql.autoBroadcastJoinThreshold':'-1'}\n",
    "})).toPandas()\n",
    "#提取对照组的参与者数据，并且用Spark方式来执行。\n",
    "cont_only = cont_df[~cont_df['eid'].isin(case_df['eid'])]#在提取对照组的cohort时，把case的患者放进来了，所以增加了这步\n",
    "df = pd.concat([case_df, cont_only])\n",
    "df.shape\n",
    "\n",
    "#f. Create phenotype variable\n",
    "#在 df 里新建了一列叫 urticaria_cc，并且给这一列的所有行都赋初值为 0。\n",
    "df['urticaria_cc'] = 0\n",
    "#把那些在 case_df里的参与者标记为 1，其他保持 0。\n",
    "df.loc[df.eid.isin(case_df.eid),'urticaria_cc'] = 1\n",
    "#统计列中每个取值（0 和 1）出现的次数。\n",
    "df.urticaria_cc.value_counts()\n",
    "df.head()\n",
    "\n",
    "#g. filter samples\n",
    "df_qced = df [\n",
    "(df['p31'] == df['p22001']) & #Check gender and genetic sex are the same\n",
    "(df['p22006'] == 1)& #Check participant has white british ancestry\n",
    "(df['p22019'].isnull())& # Check No sex chromosome aneuploidy\n",
    "(df['p22021'] == 0) #No kinship found\n",
    "]\n",
    "df_qced.urticaria_cc.value_counts() #查看筛选后的participant数量\n",
    "\n",
    "#h. select and rename phenotype and covariate columns\n",
    "df_qced = df_qced.rename(columns={\n",
    "    'eid': 'IID',\n",
    "    'p31': 'sex',\n",
    "    'p21022': 'age',\n",
    "    'p20160_i0': 'ever_smoked',\n",
    "    'p22006': 'ethnic_group',\n",
    "    'p22019': 'sex_chromosome_aneuploidy',\n",
    "    'p22021': 'kinship_to_other_participants'\n",
    "}) #重命名列\n",
    "\n",
    "df_qced['FID'] = df_qced['IID'] #新增FID列，Regenie要求输入表中必须包含 FID 和 IID 两列\n",
    "df_phenotype = df_qced[['FID', 'IID', 'urticaria_cc', 'sex', 'age', 'ever_smoked']] #从 QC 过的数据中挑出真正要用于 GWAS 的关键变量，生成最终的 phenotype 表。\n",
    "\n",
    "df_qced.head()\n",
    "df_qced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e03d5c6b-65c2-49dc-9bae-8817242490c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237209, 6)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################Select only samples that have WES data available##############\n",
    "# Get WES（.fam 是 PLINK 格式的一种文件，主要存放样本的家族结构和性别等基本信息。）\n",
    "exome_folder = 'Population level exome OQFE variants, PLINK format - final release'#再此用的是final release，可以有自由选择。\n",
    "exome_field_id = '23158' #这个文件夹里所有文件的field id都是23158\n",
    "output_dir = '/Data/'\n",
    "\n",
    "#只读了c1_b0_v1.fam，是因为所有的.fam文件都是一样的，可以查看md5来验证,详见最下方。\n",
    "path_to_family_file = f'/mnt/project/Bulk/Exome sequences/{exome_folder}/ukb{exome_field_id}_c1_b0_v1.fam'\n",
    "plink_fam_df = pd.read_csv(path_to_family_file,  sep=r'\\s+', dtype='object',                           \n",
    "                           names = ['FID','IID','Father ID','Mother ID', 'sex', 'Pheno'], engine='python')\n",
    "\n",
    "# Intersect the phenotype file and the WES .fam file\n",
    "# to generate phenotype DataFrame for the participants\n",
    "urticaria_wes_df = df_phenotype.join(plink_fam_df.set_index('IID'), on='IID', rsuffix='_fam', how='inner')\n",
    "\n",
    "# Drop unuseful columns from .fam file\n",
    "urticaria_wes_df.drop(\n",
    "    columns=['FID_fam','Father ID','Mother ID','sex_fam', 'Pheno'], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "# Write phenotype files to a TSV file\n",
    "urticaria_wes_df.to_csv('urticaria_wes.phe', sep='\\t', na_rep='NA', index=False, quoting=3)\n",
    "urticaria_wes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb18fcdd-6fe8-40da-ba51-fc82f10394cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-J3xZ4Q8J3g3XFjKvf9Gp3YVP\n"
     ]
    }
   ],
   "source": [
    "############### Upload the geno-pheno intersect phenotype file back to the RAP project###########\n",
    "%%bash -s \"$output_dir\"\n",
    "dx upload urticaria_wes.phe -p --path $1 --brief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a61a4a13-9252-4015-9163-1e51a054edc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#校验文件fam文件是否一致\n",
    "import glob, pandas as pd, hashlib\n",
    "\n",
    "fam_paths = sorted(glob.glob(f'/mnt/project/Bulk/Exome sequences/{exome_folder}/ukb{exome_field_id}_c*_b0_v1.fam'))\n",
    "# 读取第一个 fam 作为样本清单\n",
    "plink_fam_df = pd.read_csv(\n",
    "    fam_paths[0],\n",
    "    sep=r'\\s+',       #空格和tab都可以识别\n",
    "    dtype='object',\n",
    "    names=['FID','IID','Father ID','Mother ID','sex','Pheno']\n",
    ")\n",
    "\n",
    "# 一致性校验\n",
    "def md5(p): \n",
    "    with open(p, 'rb') as f: \n",
    "        return hashlib.md5(f.read()).hexdigest()\n",
    "\n",
    "assert len({md5(p) for p in fam_paths}) == 1, \"Not all .fam files are identical!\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
